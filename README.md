# Практическая работа 1 — Kafka (Python)

Тема: «Настройка кластера и реализация продюсера с двумя консьюмерами»
## Коротко
Решение на Python. В репозитории:
- docker-compose для запуска Zookeeper + 3 Kafka brokers
- Приложение `app/` с producer.py, single_consumer.py, batch_consumer.py
- Сериализация: JSON (класс MyMessage)
- Гарантии доставки: At Least Once (producer: `acks='all'`, `retries=5`; consumers: manual commit у batch consumer)

## Файлы
- `docker-compose.yml` — поднять кластер.
- `topic.txt` — команда создания топика и пример `--describe`.
- `app/` — код приложения и Dockerfile.

## Запуск (локально, на машине с Docker)
1. Склонируйте репозиторий:
2. Запустите кластер:
(если хотите запустить приложение в двух экземплярах: `docker-compose up --build --scale app=2`)

Примечание: `--scale` работает без swarm и поднимет несколько контейнеров сервиса `app`. Вы также можете запускать producer/consumer вручную через `docker-compose run`.

3. Создайте топик (внутри контейнера kafka1 либо на вашей машине, если у вас установлен Kafka CLI):

4. Запуск приложения:
- Через контейнер (пример):
  ```
  # запустить продюсер
  docker-compose run --rm app python producer.py

  # в другом окне запустить single consumer
  docker-compose run --rm app python single_consumer.py

  # в третьем окне запустить batch consumer
  docker-compose run --rm app python batch_consumer.py
  ```

- Или запустить два экземпляра приложения:
  ```
  docker-compose up --build --scale app=2
  ```
  (после этого контейнеры app будут запущены; по умолчанию `CMD` в Dockerfile запускает `producer.py` — можно переопределить при старте.)

## Как проверить требования задания
1. Топик создан с 3 партициями и replication factor 2 — см. `topic.txt` и вывод `kafka-topics.sh --describe`.
2. Продюсер отправляет сообщения в топик (в логах увидите `Sending: {...}` и сообщения о доставке при успешном callback).
3. `SingleMessageConsumer`:
- читает сообщения по одному,
- использует авто-коммит (`enable_auto_commit=True`).
4. `BatchMessageConsumer`:
- собирает минимум 10 сообщений (`min_batch_size = 10`),
- после обработки всей пачки вызывает `consumer.commit()`.
5. Сериализация/десериализация:
- Класс `MyMessage` → `to_json()` и `from_json()` (в `message.py`).
- При ошибке сериализации/десериализации — логируем и продолжаем.
6. Гарантии доставки:
- Producer: `acks='all'`, `retries=5` → At Least Once.
- Batch consumer: ручной коммит после успешной обработки пачки (в случае ошибки — не коммитим, сообщения будут повторно прочитаны).
7. Логи при ошибках — в консоль (через logging), приложение продолжает работать.

## Комментарии в коде (что за что отвечает)
В коде (producer/consumer) есть комментарии. Коротко:
- `acks='all'` — ждать подтверждения от всех ISR (сильнее, чем acks=1).
- `retries` — количество повторных попыток отправки.
- `enable_auto_commit` — если True, client сам периодически коммитит офсеты.
- `consumer.commit()` — ручной (синхронный) коммит после успешной обработки пачки.

## Проверка работы (шаги)
1. Убедитесь, что топик `my-topic` существует и имеет 3 партиции.
2. Запустите `producer.py` — он начнёт печатать отправляемые сообщения.
3. Запустите оба консьюмера:
- `single_consumer.py` будет выводить каждое сообщение при получении.
- `batch_consumer.py` будет собирать пачки по 10 и разом их обрабатывать + коммитить.
4. Сделайте задержку/симуляцию ошибки в `batch_consumer.py` (например бросьте исключение в цикле обработки) — проверьте, что при ошибке пакет не коммитится и повторно читается (того же или другого консьюмера с другим `group_id`).


